[["index.html", "SQL cookbook Preface", " SQL cookbook Qiushi Yan 2020-11-28 Preface This document includes query solutions and techniques to common questions in data analysis. Queries will typically be interpreted with the PostgreSQL dialect in knitrs sql engine. I include dplyr code when there could be some interesting comparison between these two tools sharing similar philosophy. Before each chapter, the following command is automatically evaluated: library(RPostgreSQL) library(DBI) con &lt;- dbConnect(dbDriver(&#39;PostgreSQL&#39;), # SQL engine dbname = dbname, # database name host = &quot;localhost&quot;, # either localhost or a database url port = 5432, # the defualt port user = user, # username password = password) # password By default, SELECT queries will display the first 10 records of their results within the document, in other words LIMIT 10 is appended to each query, this is controlled via knitr::opts_knit$set(sql.max.print = 10). References include: SQL Tutorial Practical SQL A Beginners Guide to Storytelling with Data (DeBarros 2018) SQL for Data Analytics: Perform fast and efficient data analysis with the power of SQL (Malik, Goldwasser, and Johnston 2019) Analyzing Big Data with SQL, a coursera course "],["sql-basics.html", "Chapter 1 SQL Basics 1.1 Data Types 1.2 DDL 1.3 Dropping and Updating Tables 1.4 DML 1.5 Creating Views 1.6 Queries", " Chapter 1 SQL Basics 1.1 Data Types 1.2 DDL CREATE: to create objects (table or database) in RDBMS ALTER: alters the structure of database DROP: delete objects from database RENAME: rename an objects 1.2.1 Creating Tables CREATE TABLE {table_name} ( {column_name_1} {data_type_1} {column_constraint_1}, {column_name_2} {data_type_2} {column_constraint_2}, {column_name_3} {data_type_3} {column_constraint_3},  {column_name_last} {data_type_last} {column_constraint_last}, ) Common data types are: The available constraints in SQL are: NOT NULL: This constraint tells that we cannot store a null value in a column. That is, if a column is specified as NOT NULL then we will not be able to store null in this particular column any more. UNIQUE: This constraint when specified with a column, tells that all the values in the column must be unique. That is, the values in any row of a column must not be repeated. PRIMARY KEY: A primary key is a field which can uniquely identify each row in a table. And this constraint is used to specify a field in a table as primary key. FOREIGN KEY: A Foreign key is a field which can uniquely identify each row in a another table. And this constraint is used to specify a field as Foreign key. CHECK: This constraint helps to validate the values of a column to meet a particular condition. That is, it helps to ensure that the value stored in a column meets a specific condition. DEFAULT: This constraint specifies a default value for the column when no value is specified by the user. 1.3 Dropping and Updating Tables DROP TABLE &lt;name&gt; is used to delete a table. What is often done is updating an old table. This requires dropping the old table if it exists, and create a new one. DROP TABLE IF EXISTS &lt;name&gt;; CREATE TABLE &lt;name&gt; as ... Note the semicolon behind name. 1.4 DML INSERT: insert data into a table UPDATE: update existing data within a table DELETE: deletes all records from a table, space Some would argue that SELECT should fall into the DML category. However, I think it is to our best advantage to make SELECT a standalone type of statements, DQL (database query language). Later chapters of this document is really focused on syntax and functions that can make the most of DQL. 1.4.1 Inserting Rows INSERT INTO table_name(column1, column2 , column3,..) VALUES (value1, value2, value3, ...), (value1, value2, value3, ...), ...; 1.5 Creating Views 1.5.1 Deleting Views 1.5.2 Updating Views 1.6 Queries Queries or DQL in SQL starts with SELECT 1.6.1 Order of Execution https://blog.jooq.org/2016/03/17/10-easy-steps-to-a-complete-understanding-of-sql/ 1.6.2 The WITH Clause https://www.geeksforgeeks.org/sql-with-clause/ WITH inventory_subset AS ( SELECT * FROM inventory WHERE shop != &#39;Dicey&#39; ) SELECT * FROM inventory_subset Fundamentally, the definition of a view is saved in the database and can be reused by any query, whereas a WITH clause (or Common Table Expression, or CTE) is tied to one specific query and can only be reused by copying. Otherwise, they will be substantially the same "],["filtering.html", "Chapter 2 Filtering 2.1 Operators 2.2 Missing Values 2.3 The HAVING Clause 2.4 Filtering by aggregation", " Chapter 2 Filtering Filtering means subset your data based on some conditions. In SQL, filtering is based on the WHERE clause 2.1 Operators Operators play a central role in filtering data, they provide a boolean value true / false based on an expression, by which the WHERE clause use to judge whether one row should be kept or excluded. For example, = is an operator that checks equality. SELECT COUNT(DISTINCT(geo_name, area_water)) FROM us_counties_2010 GROUP BY region Table 2.1: 4 records count 217 1055 1423 448 2.1.1 Comparison Operators 2.1.2 Logical Operators Logical operators enable users to combine multiple boolean expressions. Binary operators AND and OR Unary operator NOT Be mindful of order of operators: NOT (first), AND (second), OR (third). One workaround is to use parenthesis () to indicate order of operations, this makes queries more readable. SELECT CAST (region as varchar(5)), COALESCE(summary_level, &#39;0&#39;), avg(p0010001) AS pop FROM us_counties_2010 GROUP BY (region, summary_level) Table 2.2: 4 records region coalesce pop 3 050 80503 4 050 160593 2 050 63438 1 050 254918 2.1.3 Other Relational Operators 2.2 Missing Values Any rows in which the expression in the WHERE clause evaluate to false and any rows in which it evaluates to NULL, are filtered out excluded from the result set. Knitrs SQL engine displays NULL as NA in the resulting table, but remember in databases this is actually NULL. How many different games in the inventory table are located in Aisle 3 of the Dicey shop? SELECT DISTINCT game FROM inventory WHERE shop = &#39;Dicey&#39; AND aisle = 3 Table 2.3: 1 records game Monopoly The answer is at least 1. Since the row representing the game Clue in the shop Dicey has a missing value in the aisle column. You cannot rule out the possibility that this game is in Aisle 3. SELECT * FROM inventory WHERE aisle IS NULL Table 2.4: 1 records shop game qty aisle price Dicey Clue 3 NA 9.99 What if you wanted to write a WHERE clause to filter out the office in Illinois in the offices table, to return the three offices that are not in Illinois. You might try to write a WHERE clause like WHERE state_province not &lt;&gt; 'Illinois'. But this returns only two rows. SELECT * FROM offices WHERE state_province &lt;&gt; &#39;Illinois&#39; Table 2.5: 2 records office_id city state_province country a Istanbul Istanbul tr c Rosario Santa Fe ar Though row representing the Singapore office is not in the result set. Thats because the state province value in that row is null, and null not equal to Illinois evaluates to null. So that row is excluded from the results set SELECT * FROM offices Table 2.6: 4 records office_id city state_province country a Istanbul Istanbul tr b Chicago Illinois us c Rosario Santa Fe ar d Singapore NA sg But in this case, you know from context that this NULL value doesnt mean unknown, it means not applicable because Singapore does not have states or provinces. This is the type of situation where the IS DISTINCT FROM operator is useful. SELECT * FROM offices WHERE state_province IS DISTINCT FROM &#39;Illinois&#39; Table 2.7: 3 records office_id city state_province country a Istanbul Istanbul tr c Rosario Santa Fe ar d Singapore NA sg The IS DISTINCT FROM operator is like the not equals operator !=, but it treats NULL values and non NULL values as explicitly unequal. Whenever the operand on one side is NULL and the operand on the other side is not NULL, it evaluates to true. There is also a version of this operator that negates the result of the comparison, IS NOT DISTINCT FROM. This is like the equals operator, except when it compares a NULL value with a non-null value, it returns false instead of NULL. And when it compares two NULL values it returns true instead of NULL. This shorthand notation for IS NOT DISTINCT FROM, &lt;=&gt; is supported by Hive, Impala, and MySQL. 2.2.1 Conditional Functions if CASE nullif ifnull coalesce SELECT DISTINCT color FROM crayons WHERE red = 205 Table 2.8: 4 records color Mahogany Silver Antique Brass Wisteria 2.3 The HAVING Clause The WHERE clause is used before GROUP BY , because it makes more sense. The filter specified in the WHERE clause is used before grouping. After grouping, you can have a HAVING clause, which is similar to WHERE , except you can filter by aggregate values as well. In other words, the WHERE clause is used to place conditions on columns, while the HAVING clause is used to place conditions on groups. Often youll want to include the aggregate expression that you use in the HAVING clause in the SELECT list as well. So you can see the values in the column you filtered by. In this example, the query filters by sum of price times quantity. Its good to see those sum of price times quantity values for the rows that are included in the result set. So some of price times quantity is also used in the SELECT list. SELECT shop, sum(qty * price) FROM inventory GROUP BY shop HAVING sum(qty * price) &gt; 300 Table 2.9: 1 records shop sum Board Em 380 But its inconvenient to have to repeat the same expression in these two different places. So some SQL engines provide a shortcut that you can use to avoid this repetition. With some SQL engines, you can specify the aggregate expression in the SELECT list, give it an alias, and then use that alias in the HAVING clause. That way you do not need to repeat the aggregate expression twice. This shortcut works with Impala, Hive, and MySQL, but not with PostgreSQL and some other SQL engines. If youre using a different SQL engine, trying to see if it works. -- this does not work in PostgreSQL -- not run SELECT shop, sum(qty * price) AS total FROM inventory GROUP BY shop HAVING total &gt; 300 2.4 Filtering by aggregation We want to filter records based on a condition using aggregating values, e.g., find all teachers whose salary is lower than the average salary. This is when an aggregated subquery comes in handy. An aggregated subquery is an subquery in the FROM clause, alongside with the source table. First the subquery in FROM is run, producing a result (which we can think of as a table named t, and this alias is required). This attribute is added to every row of table teachers). It is this extended table that is evaluated in the WHERE clause; that is why the condition there refers to attribute a and selecting it. This is like Rs recycling rule in data frames: when you create a scalar column, the scalar is repeated to match the length of other columns. SELECT first_name, last_name, salary, a FROM teachers, (SELECT avg(salary) as a FROM teachers) as t WHERE salary &lt;=a Table 2.10: 5 records first_name last_name salary a Janet Smith 36200 43817 Samuel Cole 43500 43817 Samantha Bush 36200 43817 Betty Diaz 43500 43817 Kathleen Roush 38500 43817 Another way: use subqueries in the WHERE clause SELECT first_name, last_name, salary FROM teachers WHERE salary &lt;= ( SELECT avg(salary) FROM teachers ) Table 2.11: 5 records first_name last_name salary Janet Smith 36200 Samuel Cole 43500 Samantha Bush 36200 Betty Diaz 43500 Kathleen Roush 38500 "],["aggregating.html", "Chapter 3 Aggregating 3.1 Aggregate Functions 3.2 Rowwise Aggregation 3.3 The GROUP BY Clause 3.4 Common Aggregating Functions 3.5 NULL in Aggregation 3.6 Find distinct combinations 3.7 Percentages", " Chapter 3 Aggregating In each of the examples, the expression aggregates over all the rows, and returns a single row. Thats what makes these expressions aggregate expressions. They can combine values from multiple rows, aggregating them together. These are different from the arithmetic operations like +, -, * and /, or functions like ROUND, STRSUB , which operate independently on the values in each row, and return a column whose length equals that of the whole table. Those are called non-aggregate expressions. One need to be careful about mixing aggregate and non-aggregate operations. You can use aggregate and non-aggregate operations together in an expression as in the following examples. SELECT ROUND(AVG(salary), 1) AS avg_salary FROM employees Table 2.1: 1 records avg_salary 37081 SELECT SUM(salary * 0.5) AS avg_half_salary FROM employees Table 2.2: 1 records avg_half_salary 92702 Unfortunately, there are also invalid mix of aggregation expression and non-aggreagate expressions. Suppose we want to know the difference between ones salary and the highest salary in the table -- not run SELECT salary - max(salary) FROM employees This query will throw an error message like employees.salary must appear in the GROUP BY clause or be used in an aggregate function. For R users, this may be a bit confusing, since similar dplyr expressions work just fine: library(dplyr) employees &lt;- readr::read_csv(&quot;data/employees.csv&quot;) employees %&gt;% mutate(difference = salary - max(salary)) #&gt; # A tibble: 5 x 6 #&gt; empl_id first_name last_name salary office_id difference #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 Ambrosio Rojas 25784 c -28739 #&gt; 2 2 Val Snyder 37506 e -17017 #&gt; 3 3 Virginia Levitt 54523 b 0 #&gt; 4 4 Sabahattin Tilki 28060 a -26463 #&gt; 5 5 Lujza Csizmadia 39530 b -14993 This is because the R language recycles the one element scalar mean(salary) to match its length to salary. SQL, on the other hand, does not know how to subtract one row from multiple rows. For now, the workaround is to use subqueries. Later we will see another solution using window functions in Chapter 4. SELECT salary - (SELECT MAX(salary) FROM employees) AS difference FROM employees Table 2.5: 5 records difference -28739 -17017 0 -26463 -14993 Also, you cannot select aggregating expressions and regular columns in parallel. For example, the following query has two items in the SELECT list. -- not run SELECT first_name, max(salary) FROM employees The first is just the column reference first name, that evaluates as a scalar expression. It returns a value for each row in the employees table. The second is the aggregate expression, max salary. That returns one row that aggregates all the salary values in the employees table. 3.1 Aggregate Functions There common aggregate functions for summary statistics like MIN(), MAX(), AVG, SUM. Additionally, there are two aggregate functions that do not perform direct computation based on values of columns. DISTINCT can be used as keyword and functions alike. COUNT COUNT(*): Returns total number of records COUNT(column_name): Return number of Non Null values over the column salary. i.e 5. COUNT(DISTINCT Salary): Return number of distinct Non Null values over the column salary .i.e 4 CASE WHEN is often used in calculating proportions and percentages, the standard syntax is 3.2 Rowwise Aggregation There are functions in SQL that are designed to perform computations per row, instead of across rows. For them, we need not to worry about the unmatched length problem. For example, there are non-aggregate GREATEST() for MAX(), and LEAST for MIN() -- what is the dominant and least-used color for each crayon? SELECT red, green, blue, GREATEST(red, green, blue), LEAST(red, green, blue) FROM crayons Table 2.7: Displaying records 1 - 10 red green blue greatest least 239 219 197 239 197 205 149 117 205 117 253 217 181 253 181 120 219 226 226 120 135 169 107 169 107 255 164 116 255 116 250 231 181 250 181 159 129 112 159 112 253 124 110 253 110 35 35 35 35 35 This is much like the rowwise mechanism introduced since dplyr 1.0 crayon &lt;- readr::read_csv(&quot;data/crayons.csv&quot;) crayon %&gt;% rowwise() %&gt;% mutate(dominant = max(c(red, green, blue)), `least used` = min(c(red, green, blue))) #&gt; # A tibble: 120 x 8 #&gt; # Rowwise: #&gt; color hex red green blue pack dominant `least used` #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Almond EFDBC5 239 219 197 120 239 197 #&gt; 2 Antique Brass CD9575 205 149 117 120 205 117 #&gt; 3 Apricot FDD9B5 253 217 181 24 253 181 #&gt; 4 Aquamarine 78DBE2 120 219 226 120 226 120 #&gt; 5 Asparagus 87A96B 135 169 107 64 169 107 #&gt; 6 Atomic Tangerine FFA474 255 164 116 96 255 116 #&gt; 7 Banana Mania FAE7B5 250 231 181 120 250 181 #&gt; 8 Beaver 9F8170 159 129 112 120 159 112 #&gt; 9 Bittersweet FD7C6E 253 124 110 64 253 110 #&gt; 10 Black 232323 35 35 35 8 35 35 #&gt; # ... with 110 more rows 3.3 The GROUP BY Clause No surprise, the GROUP BY clasue works hand in hand with aggregate expressions, as group_by() does with summarize() in dplyr. SELECT min_age, COUNT(*) FROM games WHERE list_price &gt; 10 GROUP BY min_age; Table 2.9: 2 records min_age count 8 2 10 1 Grouping expressions using column aliases, available in PostgreSQL, Impala, Mysql. SELECT list_price &lt; 10 AS low_price, count(*) FROM games GROUP BY low_price Table 3.1: 2 records low_price count FALSE 3 TRUE 2 SELECT list_price &lt; 10, COUNT(*) FROM games GROUP BY list_price &lt; 10; Table 2.10: 2 records ?column? count FALSE 3 TRUE 2 SELECT (list_price) &gt; 20 AS over_20, max_players, COUNT(*) FROM games GROUP BY over_20, max_players; Table 2.11: 3 records over_20 max_players count FALSE 4 2 FALSE 6 2 TRUE 5 1 One of the major limitations of the GROUP BY clause is that it left you few choices in the SELECT list: either an aggregate expression or columns that appear in GROUP BY 3.4 Common Aggregating Functions 3.5 NULL in Aggregation The COUNT function was designed to be consistent with these other aggregate functions except in the case where you use COUNT(*). So the general rule is that aggregate functions ignore NULL values, and the one exception to that rule is when you use COUNT(*). With some SQL engines, you can specify more than one column reference or expression after the DISTINCT keyword in the COUNT function. This returns the number of unique combinations of the specified columns that exist in the data. This works in Hive, Impala, and MySQL, but not in PostgreSQL. -- this won&#39;t work in PostgreSQL SELECT COUNT(DISTINCT red, green, blue) F ROM crayons Also, with some SQL engines, you can use more than one COUNT(DISTINCT) in a SELECT list, like in this example which uses the crayons table. -- PostgreSQL allows for multiple COUNT(DISTINCT) in one select list SELECT pack, COUNT(DISTINCT red) AS red_count, COUNT(DISTINCT green) AS green_count, COUNT(DISTINCT blue) AS blue_count FROM crayons GROUP BY pack Table 3.2: 9 records pack red_count green_count blue_count 4 4 4 4 8 4 4 4 16 6 8 7 24 7 8 8 32 8 8 8 48 14 16 14 64 15 15 16 96 21 27 26 120 21 22 24 Here, the COUNT function is used three separate times in the SELECT list and the DISTINCT keyword is included in all three. So the result set has three columns giving the number of unique values in the red column, the number of unique values in the green column, and the number of unique values in the blue column. But with some other SQL engines including Impala, you are limited to only oneCOUNT(DISTINCT) per SELECT list. 3.6 Find distinct combinations Suppose we want to find distinct combinations of state and county in the census (which should not be repeated). GROUP BY can be used for this sort of task. SELECT state_us_abbreviation, geo_name FROM us_counties_2010 GROUP BY state_us_abbreviation, geo_name Table 3.3: Displaying records 1 - 10 state_us_abbreviation geo_name TX Glasscock County UT Box Elder County AR Calhoun County KY Breckinridge County NY Lewis County NE Thomas County CO Douglas County AR Hot Spring County NE Garden County IA Mitchell County Unlike in dplyr, distinct cannot be used in conjunction with group by in SQL # this works in us_counties_2010 &lt;- readr::read_csv(&quot;data/us_counties_2010.csv&quot;) us_counties_2010 %&gt;% group_by(state_us_abbreviation) %&gt;% distinct(geo_name) #&gt; # A tibble: 3,143 x 2 #&gt; # Groups: state_us_abbreviation [51] #&gt; geo_name state_us_abbreviation #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Autauga County AL #&gt; 2 Baldwin County AL #&gt; 3 Barbour County AL #&gt; 4 Bibb County AL #&gt; 5 Blount County AL #&gt; 6 Bullock County AL #&gt; 7 Butler County AL #&gt; 8 Calhoun County AL #&gt; 9 Chambers County AL #&gt; 10 Cherokee County AL #&gt; # ... with 3,133 more rows -- sql does not have a &quot;grouped&quot; distinct -- not run SELECT DISTINCT(geo_name) FROM us_counties_2010 GROUP BY state_us_abbreviation A workaround is using the array data type (Section 6.3) SELECT state_us_abbreviation, ARRAY_AGG(DISTINCT geo_name) FROM us_counties_2010 GROUP BY state_us_abbreviation LIMIT 1 Table 3.4: 1 records state_us_abbreviation array_agg AK {Aleutians East Borough,Aleutians West Census Area,Anchorage Municipality,Bethel Census Area,Bristol Bay Borough,Denali Borough,Dillingham Census Area,Fairbanks North Star Borough,Haines Borough,Hoonah-Angoon Census Area,Juneau City and Borough,Kenai Peninsula Borough,Ketchikan Gateway Borough,Kodiak Island Borough,Lake and Peninsula Borough,Matanuska-Susitna Borough,Nome Census Area,North Slope Borough,Northwest Arctic Borough,Petersburg Census Area,Prince of Wales-Hyder Census Area,Sitka City and Borough,Skagway Municipality,Southeast Fairbanks Census Area,Valdez-Cordova Census Area,Wade Hampton Census Area,Wrangell City and Borough,Yakutat City and Borough,Yukon-Koyukuk Census Area} 3.7 Percentages A common used of CASE is to compute percentage or proportion. And the trick is to let CASE do the group by job manually. Suppose we want to know each schools share in the total salary. SELECT sum(CASE WHEN school = &#39;F.D. Roosevelt HS&#39; THEN salary ELSE 0 END ) / (sum(salary) * 1.0) as porp_fd, sum(CASE WHEN school = &#39;Myers Middle School&#39; THEN salary ELSE 0 END ) / (sum(salary) * 1.0) as prop_myers FROM teachers Table 3.5: 1 records porp_fd prop_myers 0.531 0.469 The command can be easily adapted to, say, compute relative frequency. The following SQL command calculates the relative frequency of each schools teacher SELECT sum(CASE WHEN school = &#39;F.D. Roosevelt HS&#39; THEN 1 ELSE 0 END ) / (count(*) * 1.0) as freq_fd, sum(CASE WHEN school = &#39;Myers Middle School&#39; THEN 1 ELSE 0 END ) / (count(*) * 1.0) as freq_myers FROM teachers Table 3.6: 1 records freq_fd freq_myers 0.5 0.5 Yet this requires us to know all levels of school, use repeated syntax, and results in a wide data from that is often not suitable for data analysis. So this computing strategy is only useful when care about a single level or a small number of levels. An alternative is using aggregated subqueries (Section 2.4) SELECT school, sum(salary) / (max(total_salary) * 1.0) as salary_prop, count(*) / (max(total_count) * 1.0) as rel_freq FROM teachers, (SELECT sum(salary) as total_salary, count(*) as total_count FROM teachers) as t GROUP BY school Table 3.7: 2 records school salary_prop rel_freq F.D. Roosevelt HS 0.531 0.5 Myers Middle School 0.469 0.5 The trick is to first create the aggregation needed (in this case, total salary and counts) with aggregating subqueries, and rely on GROUP BY to do the calculation. Since total salary and count are scalar columns, take their max is simply to satisfy the requirements of GROUP BY. "],["window-functions.html", "Chapter 4 Window Functions 4.1 Create Rankings", " Chapter 4 Window Functions https://www.postgresql.org/docs/current/functions-window.html A window function performs a calculation across a set of table rows that are somehow related to the current row. This is comparable to the type of calculation that can be done with an aggregate function. However, window functions do not cause rows to become grouped into a single output row like non-window aggregate calls would. Instead, the rows retain their separate identities. Behind the scenes, the window function is able to access more than just the current row of the query result. SELECT {columns}, {window_func} OVER (PARTITION BY {partition_key} ORDER BY {order_key}) FROM table1 SELECT * FROM iris Table 2.1: Displaying records 1 - 10 id sepal_length sepal_width petal_length petal_width species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa 7 4.6 3.4 1.4 0.3 setosa 8 5.0 3.4 1.5 0.2 setosa 9 4.4 2.9 1.4 0.2 setosa 10 4.9 3.1 1.5 0.1 setosa SELECT id, petal_length, AVG(petal_length) OVER(PARTITION BY species) AS species_petal_length FROM iris Table 2.2: Displaying records 1 - 10 id petal_length species_petal_length 1 1.4 1.46 2 1.4 1.46 3 1.3 1.46 4 1.5 1.46 5 1.4 1.46 6 1.7 1.46 7 1.4 1.46 8 1.5 1.46 9 1.4 1.46 10 1.5 1.46 4.1 Create Rankings SELECT id, petal_length, species, RANK() OVER(ORDER BY petal_length DESC) FROM iris Table 2.3: Displaying records 1 - 10 id petal_length species rank 119 6.9 virginica 1 118 6.7 virginica 2 123 6.7 virginica 2 106 6.6 virginica 4 132 6.4 virginica 5 108 6.3 virginica 6 110 6.1 virginica 7 136 6.1 virginica 7 131 6.1 virginica 7 126 6.0 virginica 10 SELECT id, petal_length, species, DENSE_RANK() OVER(ORDER BY petal_length DESC) FROM iris Table 2.4: Displaying records 1 - 10 id petal_length species dense_rank 119 6.9 virginica 1 118 6.7 virginica 2 123 6.7 virginica 2 106 6.6 virginica 3 132 6.4 virginica 4 108 6.3 virginica 5 110 6.1 virginica 6 136 6.1 virginica 6 131 6.1 virginica 6 126 6.0 virginica 7 SELECT id, petal_length, species, RANK() OVER(PARTITION BY species ORDER BY petal_length DESC) FROM iris Table 2.5: Displaying records 1 - 10 id petal_length species rank 45 1.9 setosa 1 25 1.9 setosa 1 21 1.7 setosa 3 19 1.7 setosa 3 6 1.7 setosa 3 24 1.7 setosa 3 12 1.6 setosa 7 26 1.6 setosa 7 44 1.6 setosa 7 30 1.6 setosa 7 # dplyr readr::read_csv(&quot;data/iris.csv&quot;) %&gt;% mutate(rank = rank(desc(petal_length))) %&gt;% group_by(species) %&gt;% arrange(rank) %&gt;% select(id, petal_length, rank) #&gt; # A tibble: 150 x 4 #&gt; # Groups: species [3] #&gt; species id petal_length rank #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 virginica 119 6.9 1 #&gt; 2 virginica 118 6.7 2.5 #&gt; 3 virginica 123 6.7 2.5 #&gt; 4 virginica 106 6.6 4 #&gt; 5 virginica 132 6.4 5 #&gt; 6 virginica 108 6.3 6 #&gt; 7 virginica 110 6.1 8 #&gt; 8 virginica 131 6.1 8 #&gt; 9 virginica 136 6.1 8 #&gt; 10 virginica 101 6 10.5 #&gt; # ... with 140 more rows "],["joining.html", "Chapter 5 Joining", " Chapter 5 Joining Queries that join tables are similar in syntax to basic SELECT statements. The difference is that the query also specifies the following: The tables and columns to join, using a SQL JOIN ... ON statement The type of join to perform using variations of the JOIN keyword "],["complex-data-types.html", "Chapter 6 Complex Data Types 6.1 Converting Data Types 6.2 Date and Time 6.3 Array 6.4 JSON 6.5 Text", " Chapter 6 Complex Data Types The notion of data types underpin endless possibilities for type-specific operations. For example, we could extract the year component from a date, yet the same operation does not make any sense when applied to a string. On the other hand, regular expressions are designed for string matching problems and cannot be adapted to date. 6.1 Converting Data Types There is no guarantee that SQL will always correctly recognize the right data type for columns. 2020-11-28 means a date, but can be imported as a string. Since type-specific operations are only defined for certain data types. Its natural to think about converting some columnsn to the right data type. To change the data type of a column, we simply need to use the column::datatype format, where column is the column name, and data type is the data type you want to change the column into. :: CAST SELECT shop, SUM((price IS NULL)::int), COUNT(*) FROM inventory GROUP BY shop Table 2.1: 2 records shop sum count Board Em 1 3 Dicey 0 2 6.2 Date and Time To see your current date settings, you can use the following command: SHOW DateStyle Table 2.2: 1 records DateStyle ISO, MDY SET DateStyle=&#39;ISO, MDY&#39;; In addition to displaying dates that are input as strings, we can display the current date very simply using the current_date keywords in Postgres. Additionally, the SQL standard offers a TIMESTAMP data type. A timestamp represents a date and a time, down to a microsecond. This can be displayed via the current_timestamp keyword or the NOW() function. SELECT current_date, current_timestamp, NOW() Table 2.4: 1 records date now now 2020-11-28 2020-11-28 23:55:55 2020-11-28 23:55:55 Often, we will want to decompose our dates into their component parts. For example, we may be interested in only the year and month, but not the day, for the monthly analysis of our data. To do this, we can use the syntax EXTRACT(component FROM date). SELECT current_date, EXTRACT(year FROM current_date) AS year, EXTRACT(month FROM current_date) AS month, EXTRACT(day FROM current_date) AS day Table 2.5: 1 records date year month day 2020-11-28 2020 11 28 Similarly, we can abbreviate these components as y,mon, andd`, SELECT current_date, EXTRACT(y FROM current_date) AS year, EXTRACT(mon FROM current_date) AS month, EXTRACT(d FROM current_date) AS day Table 2.6: 1 records date year month day 2020-11-28 2020 11 28 We can also extract components like day of the week, week of the year, or quarter. Note that dow and isodow use different standard to extract day-of-week component. dow starts at 0 (Sunday) and goes up to Saturday, while isodow which starts at 1 (Monday) and goes up to 7 (Sunday) SELECT current_date, EXTRACT(isodow FROM current_date) AS day_of_week, EXTRACT(week FROM current_date) AS week_of_year, EXTRACT(quarter FROM current_date) AS quarter Table 2.7: 1 records date day_of_week week_of_year quarter 2020-11-28 6 48 4 6.3 Array https://www.postgresql.org/docs/current/functions-array.html#ARRAY-FUNCTIONS-TABLE SELECT array[1, 2, 3, 4], array_length(ARRAY[1, 2, 3, 4], 1) Table 2.8: 1 records array array_length {1,2,3,4} 4 SELECT unnest(ARRAY[1, 2, 3]) AS unnested_array Table 2.9: 3 records unnested_array 1 2 3 SELECT string_to_array(&#39;Hello my world&#39;, &#39; &#39;) Table 3.1: 1 records string_to_array {Hello,my,world} 6.4 JSON SELECT &#39;{ &quot;a&quot;: 1, &quot;b&quot;: [ {&quot;d&quot;: 4}, {&quot;d&quot;: 6}, {&quot;d&quot;: 4} ], &quot;c&quot;: 3 }&#39;::JSON -&gt; &#39;b&#39; AS data; Table 2.10: 1 records data [ {d: 4}, {d: 6}, {d: 4} ] | SELECT &#39;{ &quot;a&quot;: 1, &quot;b&quot;: [ {&quot;d&quot;: 4}, {&quot;d&quot;: 6}, {&quot;d&quot;: 4} ], &quot;c&quot;: 3 }&#39;::JSON #&gt; ARRAY[&#39;b&#39;, &#39;1&#39;, &#39;d&#39;] AS data; Table 2.11: 1 records data 6 6.5 Text "],["miscellaneous-query-techniques.html", "Chapter 7 Miscellaneous query techniques", " Chapter 7 Miscellaneous query techniques "],["subqueries.html", "Chapter 8 Subqueries", " Chapter 8 Subqueries We have encountered subqueries where we are interested the difference between ones salary and the highest salary in the employees table. SELECT salary - (SELECT MAX(salary) FROM employees) AS difference FROM employees Table 2.1: 5 records difference -28739 -17017 0 -26463 -14993 A subquery is nested inside another query. Typically, its used for a calculation or logical test that provides a value or set of data to be passed into the main portion of the query. Its syntax is not unusual: we just enclose the subquery in parentheses and use it where needed. For example, we can write a subquery that returns multiple rows and treat the results as a table in the FROM clause of the main query. Or we can create a scalar subquery that returns a single value and use it as part of an expression to filter rows via WHERE , IN , and HAVING clauses. These are the most common uses of subqueries. Adding a subquery to a WHERE clause can be useful in query statements other than SELECT . SELECT * FROM employees WHERE salary &gt;= (SELECT AVG(salary) FROM employees) Table 2.2: 3 records empl_id first_name last_name salary office_id 2 Val Snyder 37506 e 3 Virginia Levitt 54523 b 5 Lujza Csizmadia 39530 b 8.0.1 Create derived tables "],["solutions-to-sql-puzzles.html", "Chapter 9 Solutions to SQL puzzles", " Chapter 9 Solutions to SQL puzzles This chapter provides subjective solutions to common SQL puzzles, coming from interview questions and difficult-level problems in various SQL tutorials. "],["references.html", "References", " References DeBarros, A. 2018. Practical SQL: A Beginners Guide to Storytelling with Data. No Starch Press. https://books.google.com/books?id=xbbRAQAACAAJ. Malik, U., M. Goldwasser, and B. Johnston. 2019. SQL for Data Analytics: Perform Fast and Efficient Data Analysis with the Power of SQL. Packt Publishing. https://books.google.com/books?id=jfAXxQEACAAJ. "],["traditional-relational-database-management-systems.html", "A Traditional Relational Database Management Systems A.1 Normalization and Denormaliztion A.2 Dattabase transactions", " A Traditional Relational Database Management Systems A.1 Normalization and Denormaliztion A.2 Dattabase transactions "],["big-data-databases-and-sql.html", "B Big Data, Databases and SQL B.1 Strength and Limitaions of RDBMS B.2 Big Databases, Big Data Stores, and SQL B.3 SQL for Big Data Analysis", " B Big Data, Databases and SQL B.1 Strength and Limitaions of RDBMS B.1.1 Strength of RDBMS B.1.2 Limitations of RDBMS in the Age of Big Data limited capability of analyzing unstructured and unstructured data B.2 Big Databases, Big Data Stores, and SQL Analytic systems (data warehouses) Operational systems Non-transactional, unstructured and semi-structured Non-transactional, structured ACID-compliant RDBMSs Search engines B.2.1 Big Data Analytic Databases (Data Warehouses) good for deep analysis Apache Impala, Apache Hive, Apache Drill, presto Oracle, Teradata B.2.2 NoSQL Databases good for carefully focused operational applications provide simple DML and query commands and they physically organize records to a specific lookup key. Apache HBase: binary array cassandra: various data types mongoDB, Couchbase: JSON-like structure NoSQL databases perform well if we only have a few defined patterns for accessing data. B.2.3 Non-transactional databases Some database systems lies in the middle of NoSQL databases and traditional RDBMS systems, they are called non-transactional system, for structured tables. Apache kudu table structure enforce primary key constraints, but not foreign key constraints allow single DML on individual rows does not allow multi-row ACID-compliant transactions B.2.4 Big Data ACID-Compliant RDBMSs Based on Apache HBase, add relational data structure B.2.5 Search engines not exactly focused on operations or analysis, but specialize in quick and flexible look-ups. Solr, elasticsearch B.3 SQL for Big Data Analysis difficulties (expanding ACID-compliant system at larger scaled) distributed transactions data variety (limitations of schema on write) features kept SELECT systems, including multi-table SELECTs seeing data as tables with column names DDL and DCL features dropped, no transactions means no constraints on unique columns primary key constraints and foreign key constraints synchronized indexes (need to rebuild) triggers and stored procedures UPDATE and DELETE statements for some (cannot update file in place) features add table partitions support for many file formats csv, tsv and other deliminated files, json, XML binary file format: Apache AVRO and Apache Parquet complex data types ARRAY: list column MAP: nested tibble STRUCT "],["using-apache-hive-and-impala.html", "C Using Apache Hive and Impala C.1 Apache Hive C.2 Apache Impala", " C Using Apache Hive and Impala use command line interface to query data Beeline for Hive, use JDBC Impala Shell for Impala, doesnt use ODBC or JDBC to connect to Impala. It uses a different interface called Apache Thrift C.1 Apache Hive starting hive using beeline beeline -u jdbc:hive2://localhost:10000/fly -n training -p training -ur url -n name -p password query must end with a semicolon ;. Use !quit (without semicolon because it is not a query) to quit beeline C.2 Apache Impala start impala-shell use -h (help) to see additional arguments impala-shell -h use -d to set current database impala-shell -d fun use quit; (without exclamation, and with semicolon) to quit impala "]]
