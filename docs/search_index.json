[
["index.html", "Data Manipulation with SQL Preface", " Data Manipulation with SQL Qiushi Yan 2020-07-30 Preface This document covers essential SQL skills for data manipulation, with a main focus on DQL (Data Query Language, always starts with SELECT). Quries will typically be interpreted with the PostgreSQL dialect in knitr’s sql engine. I include dplyr code when there could be some interesting comparison between these two tools sharing similar philosophy. Before each chapter, the following command is automatically evaluated: library(RPostgreSQL) library(DBI) con &lt;- dbConnect(dbDriver(&#39;PostgreSQL&#39;), # SQL engine dbname = dbname, # database name host = &quot;localhost&quot;, # either localhost or a database url port = 5432, # the defualt port user = user, # username password = password) # password By default, SELECT queries will display the first 10 records of their results within the document, in other words LIMIT 10 is appended to each query, this is controlled via knitr::opts_knit$set(sql.max.print = 10). References include: Coursera course Analyzing Big Data with SQL SQL Tutorial Practical SQL A Beginner’s Guide to Storytelling with Data (DeBarros 2018) SQL for Data Analytics: Perform fast and efficient data analysis with the power of SQL (Malik, Goldwasser, and Johnston 2019) "],
["sql-basics.html", "Chapter 1 SQL basics 1.1 DDL 1.2 DML 1.3 Creating views", " Chapter 1 SQL basics 1.1 DDL CREATE: to create objects (table or database) in RDBMS ALTER: alters the structure of database DROP: delete objects from database RENAME: rename an objects 1.1.1 Creating tables CREATE TABLE {table_name} ( {column_name_1} {data_type_1} {column_constraint_1}, {column_name_2} {data_type_2} {column_constraint_2}, {column_name_3} {data_type_3} {column_constraint_3}, … {column_name_last} {data_type_last} {column_constraint_last}, ) Common data types are: The available constraints in SQL are: NOT NULL: This constraint tells that we cannot store a null value in a column. That is, if a column is specified as NOT NULL then we will not be able to store null in this particular column any more. UNIQUE: This constraint when specified with a column, tells that all the values in the column must be unique. That is, the values in any row of a column must not be repeated. PRIMARY KEY: A primary key is a field which can uniquely identify each row in a table. And this constraint is used to specify a field in a table as primary key. FOREIGN KEY: A Foreign key is a field which can uniquely identify each row in a another table. And this constraint is used to specify a field as Foreign key. CHECK: This constraint helps to validate the values of a column to meet a particular condition. That is, it helps to ensure that the value stored in a column meets a specific condition. DEFAULT: This constraint specifies a default value for the column when no value is specified by the user. 1.1.2 Deleting tables 1.2 DML INSERT: insert data into a table UPDATE: update existing data within a table DELETE: deletes all records from a table, space Some would argue that SELECT should fall into the DML category. However, I think it is to our best advantage to make SELECT a standalone type of statements, DQL (database query language). Later chapters of this document is really focused on syntax and functions that can make the most of DQL. 1.2.1 Inserting rows INSERT INTO table_name(column1, column2 , column3,..) VALUES(value1, value2, value3..); 1.3 Creating views 1.3.1 Deleting views 1.3.2 Updating views "],
["write-simple-queries.html", "Chapter 2 Write simple queries 2.1 The WITH clause", " Chapter 2 Write simple queries 2.1 The WITH clause https://www.geeksforgeeks.org/sql-with-clause/ WITH inventory_subset AS ( SELECT * FROM inventory WHERE shop != &#39;Dicey&#39; ) SELECT * FROM inventory_subset "],
["filtering.html", "Chapter 3 Filtering 3.1 The WHERE clause 3.2 Operators 3.3 Missing values 3.4 The HAVING clause", " Chapter 3 Filtering Filtering means subset your data based on some conditions. 3.1 The WHERE clause 3.2 Operators Operators play a central role in filtering data, they provide a boolean value true / false based on an expression, by which the WHERE clause use to judge whether one row should be kept or excluded. For example, = is an operator that checks equality. SELECT COUNT(DISTINCT(geo_name, area_water)) FROM us_counties_2010 GROUP BY region Table 3.1: 4 records count 217 1055 1423 448 3.2.1 Comparison operators 3.2.2 Logical operators Logical operators enable users to combine multiple boolean expressions. Binary operators AND and OR Unary operator NOT Be mindful of order of operators: NOT (first), AND (second), OR (third). One workaround is to use parenthesis () to indicate order of operations, this makes queries more readable. SELECT CAST (region as varchar(5)), COALESCE(summary_level, &#39;0&#39;), avg(p0010001) AS pop FROM us_counties_2010 GROUP BY (region, summary_level) Table 3.2: 4 records region coalesce pop 3 050 80503 4 050 160593 2 050 63438 1 050 254918 3.2.3 Other relational operators 3.3 Missing values Any rows in which the expression in the WHERE clause evaluate to false and any rows in which it evaluates to NULL, are filtered out excluded from the result set. Knitr’s SQL engine displays NULL as NA in the resulting table, but remember in databases this is actually NULL. How many different games in the inventory table are located in Aisle 3 of the Dicey shop? SELECT DISTINCT game FROM inventory WHERE shop = &#39;Dicey&#39; AND aisle = 3 Table 3.3: 1 records game Monopoly The answer is at least 1. Since the row representing the game Clue in the shop Dicey has a missing value in the aisle column. You cannot rule out the possibility that this game is in Aisle 3. SELECT * FROM inventory WHERE aisle IS NULL Table 3.4: 1 records shop game qty aisle price Dicey Clue 3 NA 9.99 What if you wanted to write a WHERE clause to filter out the office in Illinois in the offices table, to return the three offices that are not in Illinois. You might try to write a WHERE clause like WHERE state_province not &lt;&gt; 'Illinois'. But this returns only two rows. SELECT * FROM offices WHERE state_province &lt;&gt; &#39;Illinois&#39; Table 3.5: 2 records office_id city state_province country a Istanbul Istanbul tr c Rosario Santa Fe ar Though row representing the Singapore office is not in the result set. That’s because the state province value in that row is null, and “null not equal to Illinois” evaluates to null. So that row is excluded from the results set SELECT * FROM offices Table 3.6: 4 records office_id city state_province country a Istanbul Istanbul tr b Chicago Illinois us c Rosario Santa Fe ar d Singapore NA sg But in this case, you know from context that this NULL value doesn’t mean unknown, it means not applicable because Singapore does not have states or provinces. This is the type of situation where the IS DISTINCT FROM operator is useful. SELECT * FROM offices WHERE state_province IS DISTINCT FROM &#39;Illinois&#39; Table 3.7: 3 records office_id city state_province country a Istanbul Istanbul tr c Rosario Santa Fe ar d Singapore NA sg The IS DISTINCT FROM operator is like the not equals operator !=, but it treats NULL values and non NULL values as explicitly unequal. Whenever the operand on one side is NULL and the operand on the other side is not NULL, it evaluates to true. There is also a version of this operator that negates the result of the comparison, IS NOT DISTINCT FROM. This is like the equals operator, except when it compares a NULL value with a non-null value, it returns false instead of NULL. And when it compares two NULL values it returns true instead of NULL. This shorthand notation for IS NOT DISTINCT FROM, &lt;=&gt; is supported by Hive, Impala, and MySQL. 3.3.1 Conditional functions if CASE nullif ifnull coalesce SELECT DISTINCT color FROM crayons WHERE red = 205 Table 3.8: 4 records color Mahogany Silver Antique Brass Wisteria 3.4 The HAVING clause The WHERE clause is used before GROUP BY , because it makes more sense. The filter specified in the WHERE clause is used before grouping. After grouping, you can have a HAVING clause, which is similar to WHERE , except you can filter by aggregate values as well. In other words, the WHERE clause is used to place conditions on columns, while the HAVING clause is used to place conditions on groups. Often you’ll want to include the aggregate expression that you use in the HAVING clause in the SELECT list as well. So you can see the values in the column you filtered by. In this example, the query filters by sum of price times quantity. It’s good to see those sum of price times quantity values for the rows that are included in the result set. So some of price times quantity is also used in the SELECT list. SELECT shop, sum(qty * price) FROM inventory GROUP BY shop HAVING sum(qty * price) &gt; 300 Table 3.9: 1 records shop sum Board ’Em 380 But it’s inconvenient to have to repeat the same expression in these two different places. So some SQL engines provide a shortcut that you can use to avoid this repetition. With some SQL engines, you can specify the aggregate expression in the SELECT list, give it an alias, and then use that alias in the HAVING clause. That way you do not need to repeat the aggregate expression twice. This shortcut works with Impala, Hive, and MySQL, but not with PostgreSQL and some other SQL engines. If you’re using a different SQL engine, trying to see if it works. -- this does not work in PostgreSQL -- not run SELECT shop, sum(qty * price) AS total FROM inventory GROUP BY shop HAVING total &gt; 300 "],
["aggregating.html", "Chapter 4 Aggregating 4.1 The GROUP BY clause. 4.2 NULL values in aggregation 4.3 Using GROUP BY in non-aggregating scenarios", " Chapter 4 Aggregating In each of the examples, the expression aggregates over all the rows, and returns a single row. That’s what makes these expressions aggregate expressions. They can combine values from multiple rows, aggregating them together. These are different from the expressions earlier like round, strsub , which operate independently on the values in each row. Those are called non-aggregate expressions or scalar expressions. They return one value per row. One need to be careful about mixing aggregate and scalar operations. You can use aggregate and scalar operations together in an expression as in the following examples. SELECT ROUND(AVG(salary), 1) AS avg_salary FROM employees Table 3.1: 1 records avg_salary 37081 SELECT SUM(salary * 0.5) AS avg_half_salary FROM employees Table 3.2: 1 records avg_half_salary 92702 Unfortunately, there are also invalid mix of aggregation expression and scalar expressions. -- not run SELECT salary - AVG(salary) FROM employees This query will throw an error message like “employees.salary must appear in the GROUP BY clause or be used in an aggregate function”. For R users, this may be a bit confusing, since similar dplyr expresisons work just fine: library(dplyr) employees &lt;- readr::read_csv(&quot;data/employees.csv&quot;) employees %&gt;% mutate(difference = salary - mean(salary)) #&gt; # A tibble: 5 x 6 #&gt; empl_id first_name last_name salary office_id difference #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 Ambrosio Rojas 25784 c -11297. #&gt; 2 2 Val Snyder 37506 e 425. #&gt; 3 3 Virginia Levitt 54523 b 17442. #&gt; 4 4 Sabahattin Tilki 28060 a -9021. #&gt; 5 5 Lujza Csizmadia 39530 b 2449. For now, the workaround is to use subqueries. Later we will see another solution using window functions in Chapter 5. SELECT salary - (SELECT AVG(salary) FROM employees) AS difference FROM employees Table 3.5: 5 records difference -11297 425 17442 -9021 2449 Also, you cannot use both scalar and aggregate expressions in SELECT. For example, the following query has two items in the SELECT list. -- not run SELECT first_name, sum(salary) FROM employees The first is just the column reference first name, that evaluates as a scalar expression. It returns a value for each row in the employees table. The second is the aggregate expression, sum salary. That returns just one row that aggregates all the salary values in the employees table. SELECT red, green, blue, GREATEST(red, green, blue) FROM crayons Table 3.7: Displaying records 1 - 10 red green blue greatest 239 219 197 239 205 149 117 205 253 217 181 253 120 219 226 226 135 169 107 169 255 164 116 255 250 231 181 250 159 129 112 159 253 124 110 253 35 35 35 35 4.1 The GROUP BY clause. No surprise, the GROUP BY clasue works hand in hand with aggregate expressions, as group_by() does with summarize() in dplyr. SELECT min_age, COUNT(*) FROM games WHERE list_price &gt; 10 GROUP BY min_age; Table 3.8: 2 records min_age count 8 2 10 1 Grouping expressions using column aliases, availabe in PostgreSQL, Impala, Mysql. SELECT list_price &lt; 10 AS low_price, count(*) FROM games GROUP BY low_price Table 3.9: 2 records low_price count FALSE 3 TRUE 2 SELECT list_price &lt; 10, COUNT(*) FROM games GROUP BY list_price &lt; 10; Table 4.1: 2 records ?column? count FALSE 3 TRUE 2 SELECT list_price &gt; 20 AS over_20, max_players, COUNT(*) FROM games GROUP BY over_20, max_players; Table 4.2: 3 records over_20 max_players count FALSE 4 2 FALSE 6 2 TRUE 5 1 SELECT shop, SUM((price IS NULL)::int), COUNT(*) FROM inventory GROUP BY shop Table 4.3: 2 records shop sum count Board ’Em 1 3 Dicey 0 2 4.2 NULL values in aggregation The COUNT function was designed to be consistent with these other aggregate functions except in the case where you use COUNT(*). So the general rule is that aggregate functions ignore NULL values, and the one exception to that rule is when you use COUNT(*). With some SQL engines, you can specify more than one column reference or expression after the DISTINCT keyword in the COUNT function. This returns the number of unique combinations of the specified columns that exist in the data. This works in Hive, Impala, and MySQL, but not in PostgreSQL. -- this won&#39;t work in PostgreSQL SELECT COUNT(DISTINCT red, green, blue) FROM crayons Also, with some SQL engines, you can use more than one COUNT(DISTINCT) in a SELECT list, like in this example which uses the crayons table. -- PostgreSQL allows for multiple COUNT(DISTINCT) in one select list SELECT pack, COUNT(DISTINCT red) AS red_count, COUNT(DISTINCT green) AS green_count, COUNT(DISTINCT blue) AS blue_count FROM crayons GROUP BY pack Table 4.4: 9 records pack red_count green_count blue_count 4 4 4 4 8 4 4 4 16 6 8 7 24 7 8 8 32 8 8 8 48 14 16 14 64 15 15 16 96 21 27 26 120 21 22 24 Here, the COUNT function is used three separate times in the SELECT list and the DISTINCT keyword is included in all three. So the result set has three columns giving the number of unique values in the red column, the number of unique values in the green column, and the number of unique values in the blue column. But with some other SQL engines including Impala, you are limited to only oneCOUNT(DISTINCT) per SELECT list. 4.3 Using GROUP BY in non-aggregating scenarios We may question the data quality of us_counties_2010 cencus: specifically, can there be repetition of observations on counties on the state level? We may want to use DISTINCT(geo_name) and GROUP BY state_us_abbreviation to eliminate those repetitions: -- not run SELECT DISTINCT(geo_name) FROM us_counties_2010 GROUP BY state_us_abbreviation This works in dplyr # dplyr us_counties_2010 &lt;- readr::read_csv(&quot;data/us_counties_2010.csv&quot;) us_counties_2010 %&gt;% group_by(state_us_abbreviation) %&gt;% distinct(geo_name) #&gt; # A tibble: 3,143 x 2 #&gt; # Groups: state_us_abbreviation [51] #&gt; geo_name state_us_abbreviation #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Autauga County AL #&gt; 2 Baldwin County AL #&gt; 3 Barbour County AL #&gt; 4 Bibb County AL #&gt; 5 Blount County AL #&gt; 6 Bullock County AL #&gt; 7 Butler County AL #&gt; 8 Calhoun County AL #&gt; 9 Chambers County AL #&gt; 10 Cherokee County AL #&gt; # ... with 3,133 more rows "],
["window-functions.html", "Chapter 5 Window functions 5.1 Statisticcs with window functions", " Chapter 5 Window functions SELECT office_id, first_name, salary, sum(salary) OVER (PARTITION BY office_id ORDER BY salary) AS avg_salary FROM employees ORDER BY office_id Table 3.1: 5 records office_id first_name salary avg_salary a Sabahattin 28060 28060 b Lujza 39530 39530 b Virginia 54523 94053 c Ambrosio 25784 25784 e Val 37506 37506 SELECT * FROM customers Table 3.2: 4 records cust_id name country a Arfa pk b Brendon us c Chiyo ja d Dikembe ug 5.1 Statisticcs with window functions "],
["joining.html", "Chapter 6 Joining", " Chapter 6 Joining "],
["data-types.html", "Chapter 7 Data types 7.1 Converting data types 7.2 Type-specific operations", " Chapter 7 Data types 7.1 Converting data types To change the data type of a column, we simply need to use the column::datatype format, where column is the column name, and data type is the data type you want to change the column to. :: CAST 7.2 Type-specific operations 7.2.1 Date and time To see your current settings, you can use the following command: SHOW DateStyle Table 3.1: 1 records DateStyle ISO, MDY SET DateStyle=&#39;ISO, MDY&#39;; SELECT current_date, current_timestamp, NOW() Table 3.3: 1 records date now now 2020-07-29 2020-07-30 00:46:45 2020-07-30 00:46:45 SELECT current_date, EXTRACT(year FROM current_date) AS year, EXTRACT(month FROM current_date) AS month, EXTRACT(day FROM current_date) AS day Table 3.4: 1 records date year month day 2020-07-29 2020 7 29 "],
["solutions-to-interview-questions.html", "Chapter 8 Solutions to interview questions", " Chapter 8 Solutions to interview questions This chapter provides subjective solutions to common SQL interview questions. "],
["references.html", "References", " References DeBarros, A. 2018. Practical Sql: A Beginner’s Guide to Storytelling with Data. No Starch Press. https://books.google.com/books?id=xbbRAQAACAAJ. Malik, U., M. Goldwasser, and B. Johnston. 2019. SQL for Data Analytics: Perform Fast and Efficient Data Analysis with the Power of Sql. Packt Publishing. https://books.google.com/books?id=jfAXxQEACAAJ. "]
]
